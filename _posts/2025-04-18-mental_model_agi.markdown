---
layout: post
title: "Mental Model: AGI and Timelines"
categories: mental_models,
tags: mental_models, ai, agi
---

Original Post Date: Apr. 18, 2025
Last Updated: Apr. 19, 2025

_Disclaimer - I'm getting this out of my head for my own sake and will improve these posts as I have the time. Engage at your own risk._

<br/>

---

<br/>

## Overview

There's a lot of discussion right now about what constitutes AGI, what are AGI timelines, when work is going to get automated, when we'll have an explosion in GDP rates, etc...
This is my mental model for how I think about these questions.

## A definition of `IMPORTANT THINGS` or "what do people actually care about?"

- Their life
  - physical wellbeing
  - mental wellbeing
  - lifespan
- Their liberty
  - do what they want
  - say what they want
  - be who they want
- Their ability to pursue happiness
  - access to opportunity
  - access to resources
  - access to community
  - is earth a place worth living on?
  - is there a reasonable expectation of a positive future / ability to have kids who will have good lives
  - we don't hate ourselves (society is not founded on suffering (or, dystopically, not perceived to be founded on suffering))
  - there's enough expectation of social stability to make long term plans

Notably absent from th above list is "economic wellbeing". I'm considering economic wellbeing to be a proxy for the above, deeper, values.

## What is AGI?

- Technical definitions aside, "AGI" is artificial intelligence that broadly and fundamentally changes `IMPORTANT THINGS`
  - Interesting point here is that this broadens the definition of AGI to include the scaffolding we build around it
    - We weren't waiting for coal to get sufficiently advanced for the Industrial Revolution to create a step-function change to `IMPORTANT THINGS`.
    - The scaffolding of society and other technological innovation is what made the Industrial Revolution possible
  - Two words in the above definition that are doing a lot of heavy lifting:
    - "broadly" - Google's search algorithm fundamentally changed how we access information, but doesn't have the breadth of ability/impact to be termed AGI
      - To be slightly more specific about "broadly", let's say it requires having an impact in each larger category of "life", "liberty", and "pursuit of happiness"
    - "fundamentally" - some people are using ChatGPT to get medical advice, do work, and act in freeing ways they couldn't around others. But these changes aren't yet fundamental enough to peoples' lived realities to be considered AGI (though perhaps current models could be given sufficient scaffolding)
      - Though in mid-2025 I think there's still a "lack of breadth" issue with current models as well

## What could a fundamental change to each `IMPORTANT THING` look like?

### Physical wellbeing:

- personalized healthcare
- new medical discoveries
- improved monitoring of health
- greater access to healthcare for more people

### Mental Wellbeing

- You've got the world's best (therapist / meditation coach / relationship expert) in your pocket
- You're hooked up to the matrix (obviously dystopic but maybe you're technically happy)
- You're brought into connection with communities of people who are like you

### Lifespan

- Death by disease or privation is practically unknown
- By being 'uploaded', you can live forever
- Collective consciousness / transcendence

### Liberty

- General surplus of energy and resources through improved material transformations means that there's access to as much as people can practically consume
- Every person has access to space and privacy
  - Total digression: there are 57.5 million square miles of land on earth (https://www.quora.com/What-is-the-total-land-area-of-the-Earth). Assuming a population of 10b, that's 0.0057 sq. mi. or 3.6 acres per person. This is a naive / ridiculous way of looking at things, but it's a fun ballpark number.
- Freedom from tyranny
  - This is harder to imagine, but a post-AGI/ASI world may help secure liberal ideals for many
- Freedom from persecution
  - Again - better governance. Alternatively interacting with AIs provides judgement-free spaces for people to be themselves (ideally helping resolve inner turmoil but in bad scenarios enabling vice)

### Access to Opportunity

- Equality as a starting point (significantly decreasing wealth's impact on opportunity)

### Access to Resources

- Everyone has enough to not live in a scarcity mindset

### Access to Community

- The epidemics of loneliness in the first world are resolved, people have the community necessary for fulfilling lives

### The climate crisis is resolved

- People don't live in fear of collapsing ecosystems
- There is an abundance of biodiversity and everyone is able to experience it

### People don't live in constant fear of death by nuclear war, bioweapons, natural disaster, etc.

- Existential risk is so reduced that most people don't think about it (through improved communication, governance, and economic cooperation)

### We've solved factory farming modern / major causes of suffering

- Breakthroughs in chemistry and biology allow lab grown meat substitutes for factory farmed meat

## Avenues by which society changes:

- Scientific and Technological Innovation
  - New Materials
    - metals, cement, plastics, etc.
  - New Energy Sources
    - animal labor, water & wind, coal, oil, nuclear, etc.
  - Improvements to Agriculture
    - fertilizers, pesticides, genetic modification, etc.
  - Improvements to Medicine
    - antibiotics, vaccines, CRISPR, etc.
  - New Technology
    - computers, integrated circuits, internet, LLMs, quantum computing, etc.
  - New means of waging war or defending against war
    - gunpowder, nuclear weapons, AI warfare, etc.
- Governance, Social Institutions, and International Relations
  - Economic Systems & Concepts
    - Capitalism, Venture Capital, Free Trade, MMT, UBI, etc.
  - International Organizations
    - UN, WHO, NATO, World Bank, etc.
  - Forms of Governance
    - Democracy (representative, quadratic, liquid), Authoritarianism, etc.
  - War and Power Dynamics
    - Grand strategy, Mutually Assured Destruction, Soft Power, etc.

I believe that certain social institutions need to be in place in order for scientific and technological innovations to occur and accelerate. Once those institutions are in place, however, my model is that they lag behind the scientific and technological innovations that shape them by a few years to a few decades. Given that, I believe the first places people will "feel" AGI impacting `IMPORTANT THINGS` is in the areas of scientific and technological innovation.

A counter-factual to my assertion that AGI will be felt first in scientific and technological innovation could be that models plateau in ability and aren't really helpful in scientific discovery yet. Then, over the next few years, society could ramp up the scaffolding around current AI models such that they impact social institutions (shaping the nature of work, copyright, healthcare) before they meaningfully impact scientific and technological innovation. I don't find this scenario likely, though scaffolding is and will continue to be built.

## How long until we first feel the impacts of AGI?

My bear case is that people will feel AI broadly and fundamentally impacting `IMPORTANT THINGS` in 2-6 years.

### Improvements to Medicine and Access to Resources

Current SOTA models are already beginning to impact fields such as drug discovery, material science, and other areas of scientific research - though the rate to which they're accelerating those fields will become clearer over the next year or two. It seems to be that we're on track to double the rate of discovery of new molecules, drugs, cellular-interactions, and materials over the coming 1-3 years. This is even in a bear case where models plateau in the next 1-2 years (I'm basing this on what I'm picking out of Nature Magazine and other articles - I need firmer footing here). Clinical trials and challenges relating to productionizing new materials will likely push back the time until people feel this impact another 1-3 years. Still, this puts my bear-case timeline on how long until people first feel the impacts of AI in medicines and material science at 2-6 years.

### Improvements to Mental Wellbeing

Even if SOTA models barely improve over the next couple years, I think it's likely that anyone who wants therapy will have a good therapist in their pocket. I'm not saying we'll replace human therapists, but peoples' access to mental care will fundamentally shift in the near term. I believe that AI will serve as an effective first line in healthcare, helping with preventative care and enabling doctors to get holistic context on their patients despite the fragmented medical documentation landscape. I'd put my bear-case timeline on how long it takes for people to first feel the impacts of this at 1-6 years.

### Access to Opportunity

If SOTA models plateau, we will still likely see a reshaping of the types of labor people do in the next 2-6 years. This will impact intelligence workers first. The impacts will also be a result of scaffolding as much as the models themselves - as agency is required to facilitate or replace labor. This change could be either positive or negative, but the change will be fundamental for many people. A positive outcome would be that intelligence workers have their productivity multiplied and are able to spur new waves of innovation. A negative outcome could be the loss of jobs to Language Models through labor price arbitrage similar to what we've seen with off-shoring. I'm interested in exploring this more, but for now it's enough to just say that a large portion of western society will fundamentally feel the impacts of AI on their work in 2-6 years.

## Conclusion

"AGI" isn't a single technology. It's both the core technology and the ecosystem of technological and social scaffolding that enables it to broadly and fundamentally change `IMPORTANT THINGS` in peoples' lives. Even in a timeline where AI ability plateaus in the near future, scaffolding around current models will enable sufficient depth and breadth of impact to `IMPORTANT THINGS` that my definition of AGI will be achieved with 2-6 years. These changes will not roll out evenly, indeed we are already feeling deep impact in certain areas. But society as a whole will recognize that we're in a new technological era in this time frame - regardless of whether the term "AGI" is applied.

## _Post-text_

Realistically I think there will be many more changes than those I suggest above: robotics has progressed leaps and bounds, even in the worst case there's likely to be hundreds of billions more dollars invested in the space, military applications of this are being battle-tested, China's government will use this tool to attempt to control its increasingly educated and wealthy populace, deepfakes will happen and we'll need ways to detect them.... the list goes on and on. Assuming (as I do) that models also continue to fundamentally improve, this list of radical changes is only the tip of the iceberg. Given the lag time of the real world, however, I'd still say that there's a 2-year timeline on AGI unless we achieve deeply powerful ASI in the next year and a half. The degree of changes following that 2-year lag will just be drastically more profound than those outlined above.
